{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693676fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059aa763",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR =r\"C:\\Users\\ishan\\OneDrive\\Desktop\\face recog\\newf\" # <-- CHANGE THIS TO YOUR ACTUAL PATH\n",
    "\n",
    "# --- LANDMARK SETUP ---\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "\n",
    "def extract_metrics(landmarks, shape):\n",
    "    h, w = shape[:2]\n",
    "\n",
    "    def denorm(pt):\n",
    "        return np.array([pt.x * w, pt.y * h])\n",
    "\n",
    "    # Select key points\n",
    "    nose = denorm(landmarks[1])\n",
    "    left_eye = denorm(landmarks[33])\n",
    "    right_eye = denorm(landmarks[263])\n",
    "    left_mouth = denorm(landmarks[61])\n",
    "    right_mouth = denorm(landmarks[291])\n",
    "    chin = denorm(landmarks[152])\n",
    "\n",
    "    # Compute distances & ratios\n",
    "    eye_dist = np.linalg.norm(left_eye - right_eye)\n",
    "    mouth_width = np.linalg.norm(left_mouth - right_mouth)\n",
    "    face_height = np.linalg.norm(nose - chin)\n",
    "\n",
    "    return np.array([\n",
    "        eye_dist,\n",
    "        mouth_width,\n",
    "        face_height,\n",
    "        eye_dist / mouth_width if mouth_width else 0,\n",
    "        eye_dist / face_height if face_height else 0\n",
    "    ])\n",
    "\n",
    "def extract_all_face_vectors(dataset_dir):\n",
    "    person_vectors = {}\n",
    "\n",
    "    for person in os.listdir(dataset_dir):\n",
    "        person_path = os.path.join(dataset_dir, person)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "        vectors = []\n",
    "        for img_name in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            result = face_mesh.process(rgb)\n",
    "            if result.multi_face_landmarks:\n",
    "                metrics = extract_metrics(result.multi_face_landmarks[0].landmark, image.shape)\n",
    "                vectors.append(metrics)\n",
    "        if vectors:\n",
    "            person_vectors[person] = vectors\n",
    "    return person_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f289594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_pairs(person_vectors, max_pairs_per_class=500):\n",
    "    X, y = [], []\n",
    "    people = list(person_vectors.keys())\n",
    "    \n",
    "    # SAME-PERSON\n",
    "    same_pairs = []\n",
    "    for person in people:\n",
    "        vecs = person_vectors[person]\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1, len(vecs)):\n",
    "                same_pairs.append((vecs[i], vecs[j]))\n",
    "    random.shuffle(same_pairs)\n",
    "    same_pairs = same_pairs[:max_pairs_per_class]\n",
    "    for a, b in same_pairs:\n",
    "        X.append(np.concatenate([a, b]))\n",
    "        y.append(1)\n",
    "\n",
    "    # DIFFERENT-PERSON\n",
    "    diff_pairs = []\n",
    "    for i in range(len(people)):\n",
    "        for j in range(i+1, len(people)):\n",
    "            for a in person_vectors[people[i]]:\n",
    "                for b in person_vectors[people[j]]:\n",
    "                    diff_pairs.append((a, b))\n",
    "    random.shuffle(diff_pairs)\n",
    "    diff_pairs = diff_pairs[:max_pairs_per_class]\n",
    "    for a, b in diff_pairs:\n",
    "        X.append(np.concatenate([a, b]))\n",
    "        y.append(0)\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d8ee5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_vectors = extract_all_face_vectors(DATASET_DIR)\n",
    "X, y = generate_pairs(person_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce3526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c287ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class FaceMLP(nn.Module):\n",
    "    def __init__(self, input_size=10):\n",
    "        super(FaceMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f613133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, batch_size=32, val_ratio=0.2):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a237f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X, y, epochs=10, lr=0.001):\n",
    "    train_loader, val_loader = prepare_data(X, y)\n",
    "\n",
    "    model = FaceMLP(input_size=X.shape[1]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                predicted = (preds > 0.5).float()\n",
    "                correct += (predicted == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f} - Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "423e93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 19.7031 - Val Accuracy: 0.5400\n",
      "Epoch 2/10 - Loss: 17.9579 - Val Accuracy: 0.5250\n",
      "Epoch 3/10 - Loss: 18.0786 - Val Accuracy: 0.4900\n",
      "Epoch 4/10 - Loss: 17.4013 - Val Accuracy: 0.5150\n",
      "Epoch 5/10 - Loss: 17.5925 - Val Accuracy: 0.4900\n",
      "Epoch 6/10 - Loss: 17.7954 - Val Accuracy: 0.5100\n",
      "Epoch 7/10 - Loss: 17.3125 - Val Accuracy: 0.4800\n",
      "Epoch 8/10 - Loss: 17.2738 - Val Accuracy: 0.5000\n",
      "Epoch 9/10 - Loss: 17.4300 - Val Accuracy: 0.5200\n",
      "Epoch 10/10 - Loss: 17.6084 - Val Accuracy: 0.5350\n"
     ]
    }
   ],
   "source": [
    "model = train_mlp(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c3f7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfc1778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ecb029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 500, 0: 500})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
